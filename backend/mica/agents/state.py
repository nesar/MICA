"""
MICA Agent State Definitions

Defines the state schema used by the LangGraph orchestration system.
The state flows through the workflow and tracks all information needed
for the multi-agent analysis process.
"""

from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional, TypedDict

from langchain_core.messages import BaseMessage


class WorkflowStatus(str, Enum):
    """Status of the overall workflow."""

    INITIAL = "initial"
    RESEARCHING = "researching"
    PLAN_PROPOSED = "plan_proposed"
    AWAITING_APPROVAL = "awaiting_approval"
    EXECUTING = "executing"
    COMPLETED = "completed"
    AWAITING_FEEDBACK = "awaiting_feedback"
    FAILED = "failed"
    CANCELLED = "cancelled"


class PlanStep(TypedDict):
    """A single step in the analysis plan."""

    step_id: str
    tool: str
    description: str
    inputs: Dict[str, Any]
    status: str  # pending, running, completed, failed
    output: Optional[Any]
    error: Optional[str]


class AgentState(TypedDict):
    """
    Main state for the MICA orchestration workflow.

    This state is passed through all nodes in the LangGraph workflow
    and tracks the full context of an analysis session.
    """

    # Session information
    session_id: str
    created_at: str
    user_id: Optional[str]

    # Query and context
    query: str
    clarifications: List[str]

    # Messages for LLM context
    messages: List[BaseMessage]

    # Workflow status
    status: WorkflowStatus
    current_step: Optional[str]

    # Preliminary research results
    preliminary_research: Dict[str, Any]

    # Proposed analysis plan
    plan: List[PlanStep]
    plan_reasoning: str

    # User approval
    approved: Optional[bool]
    approval_feedback: Optional[str]

    # Execution results
    tool_results: Dict[str, Any]
    intermediate_outputs: List[Dict[str, Any]]

    # Final output
    final_summary: Optional[str]
    final_report_path: Optional[str]
    artifacts: List[Dict[str, Any]]

    # Error handling
    errors: List[Dict[str, str]]

    # Metadata
    metadata: Dict[str, Any]


def create_initial_state(
    session_id: str,
    query: str,
    user_id: Optional[str] = None,
) -> AgentState:
    """
    Create a fresh initial state for a new workflow.

    Args:
        session_id: Unique session identifier
        query: User's initial query
        user_id: Optional user identifier

    Returns:
        Initialized AgentState
    """
    return AgentState(
        # Session
        session_id=session_id,
        created_at=datetime.utcnow().isoformat(),
        user_id=user_id,
        # Query
        query=query,
        clarifications=[],
        # Messages
        messages=[],
        # Status
        status=WorkflowStatus.INITIAL,
        current_step=None,
        # Research
        preliminary_research={},
        # Plan
        plan=[],
        plan_reasoning="",
        # Approval
        approved=None,
        approval_feedback=None,
        # Results
        tool_results={},
        intermediate_outputs=[],
        # Output
        final_summary=None,
        final_report_path=None,
        artifacts=[],
        # Errors
        errors=[],
        # Metadata
        metadata={},
    )


def add_error(state: AgentState, error: str, context: Optional[str] = None) -> AgentState:
    """Add an error to the state."""
    error_entry = {
        "error": error,
        "context": context,
        "timestamp": datetime.utcnow().isoformat(),
    }
    state["errors"].append(error_entry)
    return state


def add_artifact(
    state: AgentState,
    name: str,
    artifact_type: str,
    path: Optional[str] = None,
    data: Optional[Any] = None,
) -> AgentState:
    """Add an artifact to the state."""
    artifact = {
        "name": name,
        "type": artifact_type,
        "path": path,
        "data": data,
        "created_at": datetime.utcnow().isoformat(),
    }
    state["artifacts"].append(artifact)
    return state


def update_plan_step(
    state: AgentState,
    step_id: str,
    status: str,
    output: Optional[Any] = None,
    error: Optional[str] = None,
) -> AgentState:
    """Update the status of a plan step."""
    for step in state["plan"]:
        if step["step_id"] == step_id:
            step["status"] = status
            if output is not None:
                step["output"] = output
            if error is not None:
                step["error"] = error
            break
    return state


@dataclass
class ToolCall:
    """Represents a tool call to be executed."""

    tool_name: str
    inputs: Dict[str, Any]
    step_id: Optional[str] = None

    def to_dict(self) -> dict:
        return {
            "tool_name": self.tool_name,
            "inputs": self.inputs,
            "step_id": self.step_id,
        }


@dataclass
class AnalysisPlan:
    """
    Structured analysis plan generated by the orchestrator.

    Contains the reasoning and steps for analyzing the user's query.
    """

    reasoning: str
    steps: List[PlanStep]
    estimated_tools: List[str]
    requires_simulation: bool = False
    requires_web_search: bool = False
    requires_document_analysis: bool = False

    def to_state_format(self) -> tuple[List[PlanStep], str]:
        """Convert to format used in AgentState."""
        return self.steps, self.reasoning

    @classmethod
    def from_llm_response(cls, response: str, step_counter: int = 0) -> "AnalysisPlan":
        """
        Parse an analysis plan from LLM response.

        Handles formats like:
        - ## Step 1: Title
          **Tool:** tool_name
          **Inputs:** ...
        - Simple numbered lists
        """
        import re

        steps = []
        reasoning = response
        current_step_num = step_counter

        # Tool name mapping
        tool_mapping = {
            "web_search": "web_search",
            "websearch": "web_search",
            "search": "web_search",
            "pdf_rag": "pdf_rag",
            "pdf": "pdf_rag",
            "rag": "pdf_rag",
            "excel_handler": "excel_handler",
            "excel": "excel_handler",
            "code_agent": "code_agent",
            "code": "code_agent",
            "python": "code_agent",
            "analysis": "code_agent",
            "simulation": "simulation",
            "simulate": "simulation",
            "doc_generator": "doc_generator",
            "document": "doc_generator",
            "report": "doc_generator",
            # Local database tools
            "local_doc_search": "local_doc_search",
            "local_document_search": "local_doc_search",
            "local_docs": "local_doc_search",
            "local_pdf": "local_doc_search",
            "local_data_analysis": "local_data_analysis",
            "local_data": "local_data_analysis",
            "local_excel": "local_data_analysis",
            "data_analysis": "local_data_analysis",
        }

        # Try to parse structured format with ## Step headers
        # Flexible pattern: 2-4 hashes, optional bold/asterisks, "Step N:" format
        step_pattern = r'#{2,4}\s*\*{0,2}\s*Step\s*\d+[:\s\*]+([^\n]+)'
        # Tool pattern: handle **Tool:** or - **Tool**: with optional backticks around tool name
        tool_pattern = r'\*\*Tool\*?\*?[:\s]*[`\']?([a-z_]+)[`\']?'

        step_headers = list(re.finditer(step_pattern, response, re.IGNORECASE))

        if step_headers:
            # Parse structured format
            for i, match in enumerate(step_headers):
                step_title = match.group(1).strip()
                # Clean up any trailing asterisks or formatting
                step_title = re.sub(r'\*+$', '', step_title).strip()

                # Find the content between this step and the next
                start_pos = match.end()
                end_pos = step_headers[i + 1].start() if i + 1 < len(step_headers) else len(response)
                step_content = response[start_pos:end_pos]

                # Extract tool from **Tool:** line (multiple patterns)
                tool_match = re.search(tool_pattern, step_content, re.IGNORECASE)
                if not tool_match:
                    # Try alternative: - **Tool**: `tool_name`
                    tool_match = re.search(r'-\s*\*\*Tool\*?\*?[:\s]*[`\']?([a-z_]+)', step_content, re.IGNORECASE)
                if not tool_match:
                    # Try: Tool: tool_name (no bold)
                    tool_match = re.search(r'Tool[:\s]+[`\']?([a-z_]+)', step_content, re.IGNORECASE)

                if tool_match:
                    tool_name = tool_match.group(1).lower().strip()
                    tool = tool_mapping.get(tool_name, "orchestrator")
                else:
                    # Infer tool from step title/content
                    tool = cls._infer_tool(step_title + " " + step_content, tool_mapping)

                # Extract inputs (simplified - just capture query strings)
                inputs = {}
                input_matches = re.findall(r'"([^"]+)"', step_content)
                if input_matches:
                    inputs["queries"] = input_matches[:5]  # Limit to 5 queries

                steps.append(PlanStep(
                    step_id=f"step_{current_step_num}",
                    tool=tool,
                    description=step_title,
                    inputs=inputs,
                    status="pending",
                    output=None,
                    error=None,
                ))
                current_step_num += 1

        # If no steps found with Step pattern, try numbered list format
        if not steps:
            # Fallback: parse simple numbered list (only top-level numbered items)
            simple_step_pattern = r'^(\d+)\.\s+(.+?)(?=^\d+\.|$)'
            matches = re.findall(simple_step_pattern, response, re.MULTILINE | re.DOTALL)

            for num, step_text in matches:
                step_text = step_text.strip().split('\n')[0]  # Take first line only
                if len(step_text) < 10:  # Skip very short items
                    continue

                tool = cls._infer_tool(step_text, tool_mapping)

                steps.append(PlanStep(
                    step_id=f"step_{current_step_num}",
                    tool=tool,
                    description=step_text,
                    inputs={},
                    status="pending",
                    output=None,
                    error=None,
                ))
                current_step_num += 1

        # Limit to reasonable number of steps
        if len(steps) > 20:
            steps = steps[:20]

        estimated_tools = list(set(s["tool"] for s in steps)) if steps else []

        return cls(
            reasoning=reasoning,
            steps=steps,
            estimated_tools=estimated_tools,
            requires_simulation="simulation" in estimated_tools,
            requires_web_search="web_search" in estimated_tools,
            requires_document_analysis="pdf_rag" in estimated_tools,
        )

    @classmethod
    def _infer_tool(cls, text: str, tool_mapping: dict) -> str:
        """Infer tool from text content."""
        text_lower = text.lower()

        # Check for local database tools first (they should be preferred)
        if any(w in text_lower for w in ["local doc", "local pdf", "local document", "database doc"]):
            return "local_doc_search"
        elif any(w in text_lower for w in ["local data", "local excel", "local csv", "database data"]):
            return "local_data_analysis"
        # Web search for external sources
        elif any(w in text_lower for w in ["search", "find", "look up", "query", "usgs", "federal"]):
            return "web_search"
        elif any(w in text_lower for w in ["pdf", "document analysis", "extract from"]):
            return "pdf_rag"
        elif any(w in text_lower for w in ["excel", "spreadsheet", "csv"]):
            return "excel_handler"
        elif any(w in text_lower for w in ["analyze", "calculate", "compute", "visuali", "plot", "chart", "graph"]):
            return "code_agent"
        elif any(w in text_lower for w in ["simulat", "model run", "scenario"]):
            return "simulation"
        elif any(w in text_lower for w in ["report", "generate", "compile", "create pdf"]):
            return "doc_generator"

        return "orchestrator"
